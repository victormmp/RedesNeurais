# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- roc(y_train, Y_hat, auc=TRUE, ci=TRUE, plot=TRUE)
set.seed(42)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- roc(y_train, Y_hat, auc=TRUE, ci=TRUE, plot=TRUE)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- roc(y_train, Y_hat, auc=TRUE, ci=TRUE, plot=TRUE)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- roc(y_train, Y_hat, auc=TRUE, ci=TRUE, plot=TRUE)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- roc(y_train, Y_hat, auc=TRUE, ci=TRUE, plot=TRUE)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- roc(y_train, Y_hat, auc=TRUE, ci=TRUE, plot=TRUE)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- roc(y_train, Y_hat, auc=TRUE, ci=TRUE, plot=TRUE)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- roc(y_train, Y_hat, auc=TRUE, ci=TRUE, plot=TRUE)
result$specificities
data("BreastCancer")
bc <- BreastCancer[complete.cases(BreastCancer),]
x <- bc[, 2:10]
y <- bc[,11]
x <- sapply(x, as.numeric)
y <- replicate(dim(bc)[1], 0)
y[which(bc[,11]== 'benign')] = -1
y[which(bc[,11]== 'malignant')] = 1
index_train = sample(seq(dim(x)[1]), as.integer(0.7*dim(x)[1]), replace=FALSE)
x_train = x[index_train,]
x_test = x[-index_train,]
y_train <- y[index_train]
y_test = y[-index_train]
evaluate <- function(y, y_hat) {
y[which(y<0)] = 0
y_hat[which(y_hat<0)] = 0
errors <- y - y_hat
false_positive <- length(errors[errors < 0])
true_positive <- length(y[y[which(errors == 0)] > 0])
false_negative <- length(errors[errors > 0])
true_negative <- length(y[y[which(errors == 0)] <= 0])
confusion_matrix <- matrix(replicate(4, 0), nrow = 2, ncol = 2)
confusion_matrix[1,1] <- true_positive
confusion_matrix[1,2] <- false_positive
confusion_matrix[2,1] <- false_negative
confusion_matrix[2,2] <- true_negative
return(list(
'y_result' = y_result,
'errors' = errors,
'mean_error'= mean(errors),
'accuracy' = (1 - mean(errors)),
'specitivity'= true_negative / (true_negative + false_positive),
'sensibility' = true_positive / (true_positive + false_negative),
'confusion_matrix' = confusion_matrix
))
}
result <- evaluate(y_train, Y_hat)
evaluate <- function(y, y_hat) {
y[which(y<0)] = 0
y_hat[which(y_hat<0)] = 0
errors <- y - y_hat
false_positive <- length(errors[errors < 0])
true_positive <- length(y[y[which(errors == 0)] > 0])
false_negative <- length(errors[errors > 0])
true_negative <- length(y[y[which(errors == 0)] <= 0])
confusion_matrix <- matrix(replicate(4, 0), nrow = 2, ncol = 2)
confusion_matrix[1,1] <- true_positive
confusion_matrix[1,2] <- false_positive
confusion_matrix[2,1] <- false_negative
confusion_matrix[2,2] <- true_negative
return(list(
'errors' = errors,
'mean_error'= mean(errors),
'accuracy' = (1 - mean(errors)),
'specitivity'= true_negative / (true_negative + false_positive),
'sensibility' = true_positive / (true_positive + false_negative),
'confusion_matrix' = confusion_matrix
))
}
result <- evaluate(y_train, Y_hat)
result$mean_error
result$errors
result$accuracy
evaluate <- function(y, y_hat) {
y[which(y<0)] = 0
y_hat[which(y_hat<0)] = 0
errors <- y - y_hat
false_positive <- length(errors[errors < 0])
true_positive <- length(y[y[which(errors == 0)] > 0])
false_negative <- length(errors[errors > 0])
true_negative <- length(y[y[which(errors == 0)] <= 0])
confusion_matrix <- matrix(replicate(4, 0), nrow = 2, ncol = 2)
confusion_matrix[1,1] <- true_positive
confusion_matrix[1,2] <- false_positive
confusion_matrix[2,1] <- false_negative
confusion_matrix[2,2] <- true_negative
return(list(
'errors' = errors,
'mean_error'= sum(abs(errors)),
'accuracy' = (1 - sum(abs(errors))),
'specitivity'= true_negative / (true_negative + false_positive),
'sensibility' = true_positive / (true_positive + false_negative),
'confusion_matrix' = confusion_matrix
))
}
result <- evaluate(y_train, Y_hat)
result$mean_error
result$errors
sum((y_test-Y_hat)^2)/4
length(y_test)
err <- sum((y_test-Y_hat)^2)/4
print(err)
data("BreastCancer")
bc <- BreastCancer[complete.cases(BreastCancer),]
x <- bc[, 2:10]
y <- bc[,11]
x <- sapply(x, as.numeric)
y <- replicate(dim(bc)[1], 0)
y[which(bc[,11]== 'benign')] = 0
y[which(bc[,11]== 'malignant')] = 1
index_train = sample(seq(dim(x)[1]), as.integer(0.7*dim(x)[1]), replace=FALSE)
x_train = x[index_train,]
x_test = x[-index_train,]
y_train <- y[index_train]
y_test = y[-index_train]
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
err <- sum((y_train-Y_hat)^2)/4
print(err)
# Test
rows <- dim(x_test)[1]
features <- dim(x_test)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_test)
H <- tanh(Xaug %*% Z)
Y_hat <- sign(H %*% W)
err <- sum((y_test-Y_hat)^2)/4
print(err)
rm(list=ls())
data("BreastCancer")
bc <- BreastCancer[complete.cases(BreastCancer),]
x <- bc[, 2:10]
y <- bc[,11]
x <- sapply(x, as.numeric)
y <- replicate(dim(bc)[1], 0)
y[which(bc[,11]== 'benign')] = -1
y[which(bc[,11]== 'malignant')] = 1
index_train = sample(seq(dim(x)[1]), as.integer(0.7*dim(x)[1]), replace=FALSE)
x_train = x[index_train,]
x_test = x[-index_train,]
y_train <- y[index_train]
y_test = y[-index_train]
y_train <- y[index_train]
y_test = y[-index_train]
Para avaliar o resultado das operações, será feito uso de uma função de performance, especificada como abaixo:
evaluate <- function(y, y_hat) {
y[which(y<0)] = 0
y_hat[which(y_hat<0)] = 0
errors <- y - y_hat
false_positive <- length(errors[errors < 0])
true_positive <- length(y[y[which(errors == 0)] > 0])
false_negative <- length(errors[errors > 0])
true_negative <- length(y[y[which(errors == 0)] <= 0])
confusion_matrix <- matrix(replicate(4, 0), nrow = 2, ncol = 2)
confusion_matrix[1,1] <- true_positive
confusion_matrix[1,2] <- false_positive
confusion_matrix[2,1] <- false_negative
confusion_matrix[2,2] <- true_negative
return(list(
'errors' = errors,
'error'= sum(abs(errors)),
'accuracy' = (1 - sum(abs(errors))),
'specitivity'= true_negative / (true_negative + false_positive),
'sensibility' = true_positive / (true_positive + false_negative),
'confusion_matrix' = confusion_matrix
))
}
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
err <- sum((y_train-Y_hat)^2)/4
print(err)
result <- evaluate(y_train, Y_hat)
result$error
result$accuracy
evaluate <- function(y, y_hat) {
y[which(y<0)] = 0
y_hat[which(y_hat<0)] = 0
errors <- y - y_hat
false_positive <- length(errors[errors < 0])
true_positive <- length(y[y[which(errors == 0)] > 0])
false_negative <- length(errors[errors > 0])
true_negative <- length(y[y[which(errors == 0)] <= 0])
confusion_matrix <- matrix(replicate(4, 0), nrow = 2, ncol = 2)
confusion_matrix[1,1] <- true_positive
confusion_matrix[1,2] <- false_positive
confusion_matrix[2,1] <- false_negative
confusion_matrix[2,2] <- true_negative
return(list(
'errors' = errors,
'error'= mean(abs(errors)),
'accuracy' = (1 - mean(abs(errors))),
'specitivity'= true_negative / (true_negative + false_positive),
'sensibility' = true_positive / (true_positive + false_negative),
'confusion_matrix' = confusion_matrix
))
}
result <- evaluate(y_train, Y_hat)
format('Porcentagem de erro: %f', result$error)
format('Porcentagem de erro: %d', result$error)
format('Porcentagem de erro: %s', result$error)
cat('Porcentagem de erro: ', result$error)
cat('Acurácia: ', result$accuracy)
cat('Sensibiliade: ', result$sensibility)
cat('Especificidade: ', result$specitivity)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- evaluate(y_train, Y_hat)
cat('Porcentagem de erro: ', result$error)
cat('Acurácia: ', result$accuracy)
cat('Sensibiliade: ', result$sensibility)
cat('Especificidade: ', result$specitivity)
sprintf('Porcentagem de erro: ', result$error)
sprintf('Porcentagem de erro: %f', result$error)
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- evaluate(y_train, Y_hat)
sprintf('Porcentagem de erro: %f', result$error)
sprintf('Acurácia: %f', result$accuracy)
sprintf('Sensibiliade: %f', result$sensibility)
sprintf('Especificidade: %f', result$specitivity)
# Chunk 1
rm(list=ls())
library(pracma)
library(corpcor)
library(mlbench)
library(pROC)
set.seed(42)
# Chunk 2
load("data2classXOR.txt")
rows <- dim(X)[1]
features <- dim(X)[2]
# Chunk 3
lim = c(min(X), max(X))
index_1 <- which(Y > 0)
class1 <- X[index_1,]
class2 <-X[-index_1,]
plot(class1[,1], class1[,2], xlim=lim, ylim=lim, col='blue', xlab='x1', ylab='x2')
par(new=T)
plot(class2[,1], class2[,2], xlim=lim, ylim=lim, col='red', xlab='', ylab='')
# Chunk 4
# Number of neurons in hidden layer
p <- 5
Z <- replicate(p, runif(features+1, -0.5, 0.5))
print('Matriz Z')
print(Z)
# Adição de um termo correspondente ao bias na entrada de cada neurônio
Xaug <- cbind(replicate(rows, 1), X)
H <- tanh(Xaug %*% Z)
# Chunk 5
W <- pseudoinverse(H) %*% Y
# Chunk 6
# Calculate Error
Y_hat <- sign(H %*% W)
err <- sum((Y-Y_hat)^2)/4
print(err)
# Chunk 7
# Test
Xaug <- cbind(replicate(features * 4, 1), X_t)
Ht <- tanh(Xaug %*% Z)
Y_hat_t <- sign(Ht %*% W)
err_t <- sum((Y_t-Y_hat_t)^2)/4
print(err_t)
# Chunk 8
p <- 10
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), X)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% Y
Y_hat <- sign(H %*% W)
err <- sum((Y-Y_hat)^2)/4
print(paste('Erro treinamento:', err))
# Test
Xaug <- cbind(replicate(features * 4, 1), X_t)
Ht <- tanh(Xaug %*% Z)
Y_hat_t <- sign(Ht %*% W)
err_t <- sum((Y_t-Y_hat_t)^2)/4
print(paste('Erro teste:',err_t))
# Chunk 9
p <- 50
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), X)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% Y
Y_hat <- sign(H %*% W)
err <- sum((Y-Y_hat)^2)/4
print(paste('Erro:', err))
# Test
Xaug <- cbind(replicate(features * 4, 1), X_t)
Ht <- tanh(Xaug %*% Z)
Y_hat_t <- sign(Ht %*% W)
err_t <- sum((Y_t-Y_hat_t)^2)/4
print(paste('Erro teste:',err_t))
# Chunk 10
p <- 100
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), X)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% Y
Y_hat <- sign(H %*% W)
err <- sum((Y-Y_hat)^2)/4
print(paste('Erro:', err))
# Test
Xaug <- cbind(replicate(features * 4, 1), X_t)
Ht <- tanh(Xaug %*% Z)
Y_hat_t <- sign(Ht %*% W)
err_t <- sum((Y_t-Y_hat_t)^2)/4
print(paste('Erro teste:',err_t))
# Chunk 11
p <- 500
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), X)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% Y
Y_hat <- sign(H %*% W)
err <- sum((Y-Y_hat)^2)/4
print(paste('Erro:', err))
# Test
Xaug <- cbind(replicate(features * 4, 1), X_t)
Ht <- tanh(Xaug %*% Z)
Y_hat_t <- sign(Ht %*% W)
err_t <- sum((Y_t-Y_hat_t)^2)/4
print(paste('Erro teste:',err_t))
# Chunk 12
errs_train <- c()
errs_test <- c()
for (p in seq(1, 1000, 10)) {
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), X)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% Y
Y_hat <- sign(H %*% W)
err <- sum((Y-Y_hat)^2)/4
errs_train <- c(errs_train, err)
# Test
Xaug <- cbind(replicate(features * 4, 1), X_t)
Ht <- tanh(Xaug %*% Z)
Y_hat_t <- sign(Ht %*% W)
err_t <- sum((Y_t-Y_hat_t)^2)/4
errs_test <- c(errs_test, err_t)
}
plot(seq(1, 1000, 10), errs_train, xlab='Números de neurônios na camada intermediária para treinamento', ylab='Erros', type='l')
# Chunk 13
plot(seq(1, 1000, 10), errs_test, xlab='Números de neurônios na camada intermediária para teste', ylab='Erros', type='l')
# Chunk 14
rm(list=ls())
data("BreastCancer")
bc <- BreastCancer[complete.cases(BreastCancer),]
x <- bc[, 2:10]
y <- bc[,11]
x <- sapply(x, as.numeric)
y <- replicate(dim(bc)[1], 0)
y[which(bc[,11]== 'benign')] = -1
y[which(bc[,11]== 'malignant')] = 1
index_train = sample(seq(dim(x)[1]), as.integer(0.7*dim(x)[1]), replace=FALSE)
x_train = x[index_train,]
x_test = x[-index_train,]
y_train <- y[index_train]
y_test = y[-index_train]
# Chunk 15
evaluate <- function(y, y_hat) {
y[which(y<0)] = 0
y_hat[which(y_hat<0)] = 0
errors <- y - y_hat
false_positive <- length(errors[errors < 0])
true_positive <- length(y[y[which(errors == 0)] > 0])
false_negative <- length(errors[errors > 0])
true_negative <- length(y[y[which(errors == 0)] <= 0])
confusion_matrix <- matrix(replicate(4, 0), nrow = 2, ncol = 2)
confusion_matrix[1,1] <- true_positive
confusion_matrix[1,2] <- false_positive
confusion_matrix[2,1] <- false_negative
confusion_matrix[2,2] <- true_negative
return(list(
'errors' = errors,
'error'= mean(abs(errors)),
'accuracy' = (1 - mean(abs(errors))),
'specitivity'= true_negative / (true_negative + false_positive),
'sensibility' = true_positive / (true_positive + false_negative),
'confusion_matrix' = confusion_matrix
))
}
# Chunk 16
rows <- dim(x_train)[1]
features <- dim(x_train)[2]
# Number of neurons in hidden layer
p <- 20
Z <- replicate(p, runif(features+1, -0.5, 0.5))
Xaug <- cbind(replicate(rows, 1), x_train)
H <- tanh(Xaug %*% Z)
W <- pseudoinverse(H) %*% y_train
# Calculate Error
Y_hat <- sign(H %*% W)
result <- evaluate(y_train, Y_hat)
sprintf('Porcentagem de erro: %f', result$error)
sprintf('Acurácia: %f', result$accuracy)
sprintf('Sensibiliade: %f', result$sensibility)
sprintf('Especificidade: %f', result$specitivity)
print(result$confusion_matrix)
err <- sum((y_train-Y_hat)^2)/4
print(err)
